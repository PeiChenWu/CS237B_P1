{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b0496fbd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 2048), dtype=tf.float32, name='classifier_input'), name='classifier_input', description=\"created by layer 'classifier_input'\") at layer \"classifier\". The following previous layers were accessed without issue: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1v/858n600x5b9gpdgk1ps72s480000gn/T/ipykernel_13310/696945998.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    189\u001b[0m         )\n\u001b[1;32m    190\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"saliency\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mcompute_and_plot_saliency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unrecognized scheme:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/1v/858n600x5b9gpdgk1ps72s480000gn/T/ipykernel_13310/696945998.py\u001b[0m in \u001b[0;36mcompute_and_plot_saliency\u001b[0;34m(model, image_path)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mlogits_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"classifier\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0mlogits_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/cs237b/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/cs237b/lib/python3.9/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m                   for t in tf.nest.flatten(inputs)]):\n\u001b[1;32m    145\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctional_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone_graph_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/cs237b/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/cs237b/lib/python3.9/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     nodes, nodes_by_depth, layers, _ = _map_graph_network(\n\u001b[0m\u001b[1;32m    230\u001b[0m         self.inputs, self.outputs)\n\u001b[1;32m    231\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/cs237b/lib/python3.9/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1034\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomputable_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1037\u001b[0m                 \u001b[0;34mf'Graph disconnected: cannot obtain value for tensor {x} '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                 \u001b[0;34mf'at layer \"{layer.name}\". The following previous layers '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 2048), dtype=tf.float32, name='classifier_input'), name='classifier_input', description=\"created by layer 'classifier_input'\") at layer \"classifier\". The following previous layers were accessed without issue: []"
     ]
    }
   ],
   "source": [
    "import argparse, pdb\n",
    "import matplotlib.pyplot as plt, numpy as np, tensorflow as tf\n",
    "\n",
    "from utils import (\n",
    "    decode_jpeg,\n",
    "    IMG_SIZE,\n",
    "    normalize_resize_image,\n",
    "    LABELS,\n",
    "    maybe_makedirs,\n",
    ")\n",
    "\n",
    "\n",
    "def compute_brute_force_classification(model, image_path, nH=8, nW=8):\n",
    "    \"\"\"\n",
    "    This function returns the probabilities of each window.\n",
    "    Inputs:\n",
    "        model: Model which is used\n",
    "        image_path: path to the image to be analysed\n",
    "        nH: number of windows in the vertical direction\n",
    "        nW: number of windows in the horizontal direction\n",
    "    Outputs:\n",
    "        window_predictions: a (nH, nW, 3) np.array.\n",
    "                            The last dim (size 3) is the probabilities\n",
    "                            of each label (cat, dog, neg)\n",
    "    HINT: normalize_resize_image  (from utils.py) will be useful here.\n",
    "    HINT: If you want to predict a single image you have to add a singular batch dimesnion:\n",
    "            [IMG_SIZE, IMG_SIZE, 3] -> [1, IMG_SIZE, IMG_SIZE, 3].\n",
    "            Similarly predict will return a [1, 3] array which you might want to squeeze into a [3] array\n",
    "    \"\"\"\n",
    "\n",
    "    # H x W x 3 numpy array (3 for each RGB color channel)\n",
    "    raw_image = decode_jpeg(image_path).numpy() #(500, 409, 3)\n",
    "\n",
    "    ######### Your code starts here #########\n",
    "    window_predictions = np.zeros((nH,nW,3))\n",
    "    h,w,c = raw_image.shape\n",
    "    \n",
    "    window_h = int(h/nH)\n",
    "    window_w = int(w/nW)\n",
    "    \n",
    "    for i in range(nH):\n",
    "        for j in range(nW):\n",
    "            window_img = raw_image[i*window_h:(i+1)*window_h,j*window_w:(j+1)*window_w,:]\n",
    "            padded_img = np.zeros((window_h+4,window_w+4,c))\n",
    "            padded_img[2:-2,2:-2,:] = window_img\n",
    "            normalized_img = normalize_resize_image(padded_img, IMG_SIZE)\n",
    "            img = np.expand_dims(normalized_img, axis=0)\n",
    "            pred = model(img)\n",
    "            window_predictions[i,j,:] = tf.reshape(pred[0,:],[3])\n",
    "\n",
    "    ######### Your code ends here #########\n",
    "\n",
    "    \n",
    "    return window_predictions\n",
    "\n",
    "\n",
    "def compute_convolutional_KxK_classification(model, image_path):\n",
    "    \"\"\"\n",
    "    Computes probabilities for each window based on the convolution layer of Inception\n",
    "    :param model:Model which is used\n",
    "    :param image_path: Path to the image to be analysed\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    raw_image = decode_jpeg(image_path).numpy() #(500, 409, 3)\n",
    "    resized_patch = normalize_resize_image(raw_image, IMG_SIZE)\n",
    "    conv_model = tf.keras.Model(\n",
    "        model.layers[0].inputs, model.layers[0].layers[-2].output\n",
    "    )\n",
    "\n",
    "    ######### Your code starts here #########\n",
    "    # Fill in the parts indicated by #FILL#. No additional lines are required.\n",
    "\n",
    "    # We want to use the output of the last convolution layer which has the shape [bs, K, K, bottleneck_size]\n",
    "\n",
    "    # First calculate K\n",
    "\n",
    "    # Next create a intermediate input structure which takes in a bottleneck tensor\n",
    "\n",
    "    # Create the classifier model which takes in the bottleneck tensor and outputs the class probabilities\n",
    "    # Note: you must reuse the weights (layers) from the trained model as well as the int_input\n",
    "\n",
    "    # Predict the ouput of the convolution layer using conv_model\n",
    "\n",
    "    # Reshape so that patches become batches and predict\n",
    "    \n",
    "    \n",
    "    K = conv_model.layers[-1].output_shape[1]\n",
    "    normarlized_img = np.expand_dims(normalize_resize_image(raw_image, IMG_SIZE), axis=0)\n",
    "    pred = conv_model(normarlized_img)\n",
    "    pred = tf.reshape(pred, (K*K,2048))\n",
    "    logits_tensor = model.get_layer(\"classifier\")\n",
    "    predictionsKxK = logits_tensor(pred)\n",
    "    \n",
    "    ######### Your code ends here #########\n",
    "\n",
    "    return np.reshape(predictionsKxK, [K, K, -1])\n",
    "\n",
    "\n",
    "def compute_and_plot_saliency(model, image_path):\n",
    "    \"\"\"\n",
    "    This function computes and plots the saliency plot.\n",
    "    You need to compute the matrix M detailed in section 3.1 in\n",
    "    K. Simonyan, A. Vedaldi, and A. Zisserman,\n",
    "    \"Deep inside convolutional networks: Visualising imageclassification models and saliency maps,\"\n",
    "    2013, Available at https://arxiv.org/abs/1312.6034.\n",
    "\n",
    "    :param model: Model which is used\n",
    "    :param image_path: Path to the image to be analysed\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    raw_image = tf.dtypes.cast(decode_jpeg(image_path), tf.float32)\n",
    "\n",
    "    logits_tensor = model.get_layer(\"classifier\")\n",
    "    logits_model = tf.keras.Model(model.input, logits_tensor.output)\n",
    "\n",
    "    with tf.GradientTape() as t:\n",
    "        ######### Your code starts here #########\n",
    "        # Fill in the parts indicated by #FILL#. No additional lines are\n",
    "        # required.\n",
    "\n",
    "        t.watch(raw_image)\n",
    "        Sc = logits_model(raw_image)\n",
    "        w = t.gradient(Sc, raw_image)\n",
    "        print(w)\n",
    "\n",
    "        ######### Your code ends here #########\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.imshow(M)\n",
    "    plt.title(\"Saliency with respect to predicted class %s\" % LABELS[top_class])\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.imshow(decode_jpeg(image_path).numpy())\n",
    "    plt.savefig(\"../plots/saliency.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_classification(image_path, classification_array):\n",
    "    nH, nW, _ = classification_array.shape\n",
    "    image_data = decode_jpeg(image_path).numpy()\n",
    "    aspect_ratio = float(image_data.shape[0]) / image_data.shape[1]\n",
    "    plt.figure(figsize=(8, 8 * aspect_ratio))\n",
    "    p1 = plt.subplot(2, 2, 1)\n",
    "    plt.imshow(classification_array[:, :, 0], interpolation=\"none\", cmap=\"jet\")\n",
    "    plt.title(\"%s probability\" % LABELS[0])\n",
    "    p1.set_aspect(aspect_ratio * nW / nH)\n",
    "    plt.colorbar()\n",
    "    p2 = plt.subplot(2, 2, 2)\n",
    "    plt.imshow(classification_array[:, :, 1], interpolation=\"none\", cmap=\"jet\")\n",
    "    plt.title(\"%s probability\" % LABELS[1])\n",
    "    p2.set_aspect(aspect_ratio * nW / nH)\n",
    "    plt.colorbar()\n",
    "    p2 = plt.subplot(2, 2, 3)\n",
    "    plt.imshow(classification_array[:, :, 2], interpolation=\"none\", cmap=\"jet\")\n",
    "    plt.title(\"%s probability\" % LABELS[2])\n",
    "    p2.set_aspect(aspect_ratio * nW / nH)\n",
    "    plt.colorbar()\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(image_data)\n",
    "    plt.savefig(\"../plots/detect.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--image\", type=str)\n",
    "    parser.add_argument(\"--scheme\", type=str)\n",
    "    FLAGS, _ = parser.parse_known_args()\n",
    "    maybe_makedirs(\"../plots\")\n",
    "\n",
    "    model = tf.keras.models.load_model(\"./trained_models/trained.h5\")\n",
    "    model.__call__ = tf.function(model.__call__)\n",
    "\n",
    "    writer = tf.summary.create_file_writer(\"retrain_logs\")\n",
    "    tf.summary.trace_on()\n",
    "\n",
    "    FLAGS.image = 'datasets/catswithdogs/001211.jpg'\n",
    "    #002034\n",
    "    FLAGS.scheme = 'saliency'\n",
    "    \n",
    "    if FLAGS.scheme == \"brute\":\n",
    "        plot_classification(\n",
    "            FLAGS.image,\n",
    "            compute_brute_force_classification(model, FLAGS.image, 8, 8),\n",
    "        )\n",
    "    elif FLAGS.scheme == \"conv\":\n",
    "        plot_classification(\n",
    "            FLAGS.image,\n",
    "            compute_convolutional_KxK_classification(model, FLAGS.image),\n",
    "        )\n",
    "    elif FLAGS.scheme == \"saliency\":\n",
    "        compute_and_plot_saliency(model, FLAGS.image)\n",
    "    else:\n",
    "        print(\"Unrecognized scheme:\", FLAGS.scheme)\n",
    "\n",
    "    with writer.as_default():\n",
    "        tf.summary.trace_export(\"detect_%s\" % FLAGS.scheme, step=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d10dfcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
