{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0496fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, pdb\n",
    "import matplotlib.pyplot as plt, numpy as np, tensorflow as tf\n",
    "\n",
    "from utils import (\n",
    "    decode_jpeg,\n",
    "    IMG_SIZE,\n",
    "    normalize_resize_image,\n",
    "    LABELS,\n",
    "    maybe_makedirs,\n",
    ")\n",
    "\n",
    "\n",
    "def compute_brute_force_classification(model, image_path, nH=8, nW=8):\n",
    "    \"\"\"\n",
    "    This function returns the probabilities of each window.\n",
    "    Inputs:\n",
    "        model: Model which is used\n",
    "        image_path: path to the image to be analysed\n",
    "        nH: number of windows in the vertical direction\n",
    "        nW: number of windows in the horizontal direction\n",
    "    Outputs:\n",
    "        window_predictions: a (nH, nW, 3) np.array.\n",
    "                            The last dim (size 3) is the probabilities\n",
    "                            of each label (cat, dog, neg)\n",
    "    HINT: normalize_resize_image  (from utils.py) will be useful here.\n",
    "    HINT: If you want to predict a single image you have to add a singular batch dimesnion:\n",
    "            [IMG_SIZE, IMG_SIZE, 3] -> [1, IMG_SIZE, IMG_SIZE, 3].\n",
    "            Similarly predict will return a [1, 3] array which you might want to squeeze into a [3] array\n",
    "    \"\"\"\n",
    "\n",
    "    # H x W x 3 numpy array (3 for each RGB color channel)\n",
    "    raw_image = decode_jpeg(image_path).numpy()\n",
    "\n",
    "    ######### Your code starts here #########\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ######### Your code ends here #########\n",
    "\n",
    "    return window_predictions\n",
    "\n",
    "\n",
    "def compute_convolutional_KxK_classification(model, image_path):\n",
    "    \"\"\"\n",
    "    Computes probabilities for each window based on the convolution layer of Inception\n",
    "    :param model:Model which is used\n",
    "    :param image_path: Path to the image to be analysed\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    raw_image = decode_jpeg(image_path).numpy()\n",
    "    resized_patch = normalize_resize_image(raw_image, IMG_SIZE)\n",
    "    conv_model = tf.keras.Model(\n",
    "        model.layers[0].inputs, model.layers[0].layers[-2].output\n",
    "    )\n",
    "\n",
    "    ######### Your code starts here #########\n",
    "    # Fill in the parts indicated by #FILL#. No additional lines are required.\n",
    "\n",
    "    # We want to use the output of the last convolution layer which has the shape [bs, K, K, bottleneck_size]\n",
    "\n",
    "    # First calculate K\n",
    "\n",
    "    # Next create a intermediate input structure which takes in a bottleneck tensor\n",
    "\n",
    "    # Create the classifier model which takes in the bottleneck tensor and outputs the class probabilities\n",
    "    # Note: you must reuse the weights (layers) from the trained model as well as the int_input\n",
    "\n",
    "    # Predict the ouput of the convolution layer using conv_model\n",
    "\n",
    "    # Reshape so that patches become batches and predict\n",
    "    ######### Your code ends here #########\n",
    "\n",
    "    return np.reshape(predictionsKxK, [K, K, -1])\n",
    "\n",
    "\n",
    "def compute_and_plot_saliency(model, image_path):\n",
    "    \"\"\"\n",
    "    This function computes and plots the saliency plot.\n",
    "    You need to compute the matrix M detailed in section 3.1 in\n",
    "    K. Simonyan, A. Vedaldi, and A. Zisserman,\n",
    "    \"Deep inside convolutional networks: Visualising imageclassification models and saliency maps,\"\n",
    "    2013, Available at https://arxiv.org/abs/1312.6034.\n",
    "\n",
    "    :param model: Model which is used\n",
    "    :param image_path: Path to the image to be analysed\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    raw_image = tf.dtypes.cast(decode_jpeg(image_path), tf.float32)\n",
    "\n",
    "    logits_tensor = model.get_layer(\"classifier\")\n",
    "    logits_model = tf.keras.Model(model.input, logits_tensor.output)\n",
    "\n",
    "    with tf.GradientTape() as t:\n",
    "        ######### Your code starts here #########\n",
    "        # Fill in the parts indicated by #FILL#. No additional lines are\n",
    "        # required.\n",
    "\n",
    "\n",
    "\n",
    "        ######### Your code ends here #########\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.imshow(M)\n",
    "    plt.title(\"Saliency with respect to predicted class %s\" % LABELS[top_class])\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.imshow(decode_jpeg(image_path).numpy())\n",
    "    plt.savefig(\"../plots/saliency.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_classification(image_path, classification_array):\n",
    "    nH, nW, _ = classification_array.shape\n",
    "    image_data = decode_jpeg(image_path).numpy()\n",
    "    aspect_ratio = float(image_data.shape[0]) / image_data.shape[1]\n",
    "    plt.figure(figsize=(8, 8 * aspect_ratio))\n",
    "    p1 = plt.subplot(2, 2, 1)\n",
    "    plt.imshow(classification_array[:, :, 0], interpolation=\"none\", cmap=\"jet\")\n",
    "    plt.title(\"%s probability\" % LABELS[0])\n",
    "    p1.set_aspect(aspect_ratio * nW / nH)\n",
    "    plt.colorbar()\n",
    "    p2 = plt.subplot(2, 2, 2)\n",
    "    plt.imshow(classification_array[:, :, 1], interpolation=\"none\", cmap=\"jet\")\n",
    "    plt.title(\"%s probability\" % LABELS[1])\n",
    "    p2.set_aspect(aspect_ratio * nW / nH)\n",
    "    plt.colorbar()\n",
    "    p2 = plt.subplot(2, 2, 3)\n",
    "    plt.imshow(classification_array[:, :, 2], interpolation=\"none\", cmap=\"jet\")\n",
    "    plt.title(\"%s probability\" % LABELS[2])\n",
    "    p2.set_aspect(aspect_ratio * nW / nH)\n",
    "    plt.colorbar()\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(image_data)\n",
    "    plt.savefig(\"../plots/detect.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--image\", type=str)\n",
    "    parser.add_argument(\"--scheme\", type=str)\n",
    "    FLAGS, _ = parser.parse_known_args()\n",
    "    maybe_makedirs(\"../plots\")\n",
    "\n",
    "    model = tf.keras.models.load_model(\"./trained_models/trained.h5\")\n",
    "    model.__call__ = tf.function(model.__call__)\n",
    "\n",
    "    writer = tf.summary.create_file_writer(\"retrain_logs\")\n",
    "    tf.summary.trace_on()\n",
    "\n",
    "    if FLAGS.scheme == \"brute\":\n",
    "        plot_classification(\n",
    "            FLAGS.image,\n",
    "            compute_brute_force_classification(model, FLAGS.image, 8, 8),\n",
    "        )\n",
    "    elif FLAGS.scheme == \"conv\":\n",
    "        plot_classification(\n",
    "            FLAGS.image,\n",
    "            compute_convolutional_KxK_classification(model, FLAGS.image),\n",
    "        )\n",
    "    elif FLAGS.scheme == \"saliency\":\n",
    "        compute_and_plot_saliency(model, FLAGS.image)\n",
    "    else:\n",
    "        print(\"Unrecognized scheme:\", FLAGS.scheme)\n",
    "\n",
    "    with writer.as_default():\n",
    "        tf.summary.trace_export(\"detect_%s\" % FLAGS.scheme, step=0)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
